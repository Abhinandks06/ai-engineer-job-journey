# AI Engineer Job Journey ðŸš€

This repository documents my journey transitioning into an **AI Engineer / Python Backend Engineer (AI-focused)** role by building **production-grade AI systems** step by step.

The focus is on **practical applied AI**, not research ML â€” aligning with real-world startup and product engineering requirements.

---

## ðŸ§  What This Project Is

A **production-ready, multi-user Retrieval-Augmented Generation (RAG) backend** built using:

- FastAPI
- Local LLMs (Ollama â€“ LLaMA 3)
- Vector databases (FAISS)
- Clean backend architecture
- Strong hallucination and data-isolation controls

This is **not a demo chatbot** â€” it is designed like a real backend service.

---

## âœ¨ Current Features

### ðŸ”¹ Backend & API
- FastAPI-based backend with clean, modular structure
- Versioned and user-scoped API endpoints
- Background tasks for non-blocking document ingestion

### ðŸ”¹ LLM Integration
- Offline LLM inference using **Ollama (LLaMA 3)**
- Strict prompt discipline (no hallucination, no self-reference)
- Confidence-aware responses

### ðŸ”¹ Retrieval-Augmented Generation (RAG)
- PDF document ingestion
- Text chunking with overlap
- Embedding generation
- FAISS vector store integration
- Source-aware answers with page-level attribution

### ðŸ”¹ Multi-User Support (Day 11)
- **Per-user document isolation**
- **Per-user FAISS vector stores**
- No shared global index
- User-scoped persistence under:

